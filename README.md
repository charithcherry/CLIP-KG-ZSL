# Enhancing Zero-Shot Learning: Integrating CLIP Embeddings with Knowledge Graphs and Graph Convolutional Networks

**Authors:** Charith Purushotham, Arjyahi Bhattacharya  
**Course:** CSCI 5922, University of Colorado Boulder

---

## ğŸ§  Introduction

Generalizing to novel, unseen concepts is a hallmark of human intelligenceâ€”an ability that current machine learning systems still struggle to replicate effectively.

In many real-world applications such as medical diagnostics, wildlife classification, and industrial defect detection, collecting labeled data for every category is impractical. This motivates **Zero-Shot Learning (ZSL)**, where models must classify unseen classes using auxiliary semantic information.

Our goal is to develop a zero-shot classification system that leverages:
- Structured **knowledge graphs**
- **CLIP** multimodal embeddings
- **Graph Convolutional Networks (R-GCNs)**

---

## âš™ï¸ Installation

```bash
# 1. Create a virtual environment
python -m venv venv

# 2. Activate the environment
# Windows
venv/Scripts/activate
# macOS/Linux
source venv/bin/activate

# 3. Install dependencies
pip install -r requirements.txt
```
---

## ğŸ“ Project Structure
```
.
â”œâ”€â”€ create_graph.py
â”œâ”€â”€ train_rgcn.py
â”œâ”€â”€ train_mlp.py
â”œâ”€â”€ Dataloader/
â”‚   â””â”€â”€ dataloader.py
â”œâ”€â”€ inference/
â”‚   â””â”€â”€ inference_pipeline.py
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ generate_clip_embeddings.py
â”‚   â””â”€â”€ image_embedding_utils.py
â”œâ”€â”€ test_module/
â”‚   â”œâ”€â”€ rgcn_test.py
â”‚   â””â”€â”€ mlp_test.py
â”œâ”€â”€ data/
â”‚   â””â”€â”€ Animals_with_Attributes2/
â”œâ”€â”€ class_wise_embeddings/
â”œâ”€â”€ test_requirements/
â”‚   â””â”€â”€ clip_requirement.py
â”œâ”€â”€ checkpoints/
â”œâ”€â”€ output/
â””â”€â”€ requirements.txt
```
---
## ğŸš€ Running the Pipeline

### ğŸ”¹ Step 1: Create the Class Relationship Graph
Constructs a weighted pairwise class graph based on the image embeddings or class hierarchy.

```bash
python create_graph.py
```
### ğŸ”¹ Step 2: Train the R-GCN Model
Trains a Relational Graph Convolutional Network using the graph and CLIP embeddings.
```bash
python train_rgcn.py \
  data/Animals_with_Attributes2/JPEGImages \
  output/filtered_class_pairwise_weighted_graph.json \
  output/
```

### ğŸ”¹ Step 3: Test the R-GCN Module
Tests the trained R-GCN by predicting class embeddings for a given test image.
```bash
python test_module/rgcn_test.py \
  --image_path data/Animals_with_Attributes2/JPEGImages/chimpanzee/chimpanzee_10501.jpg
```

### ğŸ”¹ Step 4: Generate CLIP Embeddings
Generates CLIP-based image embeddings for the dataset.
```bash
python utils/generate_clip_embeddings.py \
  data/Animals_with_Attributes2/JPEGImages/
```

### ğŸ”¹ Step 5: Train the MLP Classifier
Trains an MLP on top of the embeddings generated to learn the mapping from visual to semantic space.
```bash
python train_mlp.py \
  class_wise_embeddings/train-image-embeddings-350 \
  output/
```

### ğŸ”¹ Step 6: Test the MLP Model
Tests the final trained model on a given image and compares the predicted class to the actual.
```bash
python test_module/mlp_test.py \
  checkpoints/final_model.pt \
  output/reordered_prototypes.pt \
  data/Animals_with_Attributes2/JPEGImages/chimpanzee/chimpanzee_10501.jpg
```

### ğŸ”¹ Step 7: Full Inference Pipeline
Runs the end-to-end inference pipeline from image to predicted label.
```bash
python inference/inference_pipeline.py \
  --checkpoint_path checkpoints/final_model.pt \
  --prototype_path output/reordered_prototypes.pt \
  --embedding_dir data/image-embeddings-2.0/test-image-embeddings-20
```








